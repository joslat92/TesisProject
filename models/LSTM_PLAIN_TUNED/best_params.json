{
  "units": 64,
  "n_layers": 2,
  "dropout": 0.0,
  "learning_rate": 0.001,
  "epochs": 80,
  "batch_size": 32
}